\section{September 18}

\subsection{Review from yesterday}

\begin{tcolorbox}[title = Review]

There are circumstances where we don't know parameters of a population, but we have some information from a sample.

The only reasonable thing we can derive about a population from a sample is a mean, that if our sample is sufficiently "good" (representative), our sample mean $\overline{x}$ should be pretty close to the population mean $\mu$, or
$$\overline{x} \approx \mu$$

\end{tcolorbox}

\subsection{Sampling distributions}

Recall that as the number of rolls increases for a given trial, the distribution of our averages gets closer and closer to a normal distribution. With only one dice, all average values are equally likely, but with more and more, the probability of $\overline{x} = E[X] = 3.5$ increases and the probability of other means decreases.

We say that a given random variable $X$ is normally distributed, and we take $n$ samples. The mean of this sample approximately matches the population mean, and is centered at the same mean as well.
$$\overline{X} \approx \mu_{\overline{X}} = \mu.$$

The standard deviation of the mean of our samples (or sample means), or \textbf{standard error} is given by
$$\sigma_{\overline{X}} = \frac{\sigma_{X}}{\sqrt{n}}.$$
This is in accordance with our experiment: as the number of observations per sample increases, the standard deviation of our sample means decrease and our estimate for our mean becomes more and more accurate.

\subsection{Abnormality and CLT}

What if we don't know if our random variable is normally distributed or not? We know (or may not know) that it has \textit{some} mean $\mu_{X}$ and \textit{some} standard deviation $\sigma_{X}$.

The sample mean $\overline{X}$ matches to the population mean $\mu$ quite easily. Interestingly, so long as we take a sufficiently large $n$, \textit{the sample mean $\overline{X}$ is normally distributed.}

\begin{tcolorbox}[title = Central]

If $n$ is large enough, the sample mean $\overline{X}$ is normally distributed with paramters $\mu_{\overline{X}} = \mu_{X}$ and $\sigma_{\overline{X}} = \frac{\sigma_{X}}{\sqrt{n}}.$

\end{tcolorbox}

The consequence of this is that we can invoke any and all properties of the normal distribution to our sampling distribution.

If our $n$ is sufficiently large, we can say that we are 95\% confident in getting a sample mean $\overline{X}$ within two standard deviations $2\frac{\sigma_{X}}{\sqrt{n}}$ of the population. This is also true in reverse: if we have a sample mean $\overline{X}$, the population mean $\mu_{X}$ should be within two standard deviations $2\frac{\sigma_{X}}{\sqrt{n}}$ of the sample mean $\overline{X}$.

\subsection{When CLT fails -- bootstrapping}

What if the number of observations per sample is too small, so CLT can't reasonably kick in? Or what if we want to measure some other population parameter, like the median? We use a technique called \textbf{bootstrapping}

\begin{center} 
    \begin{tabularx}{\linewidth}{>{\raggedleft\arraybackslash}p{2in}X} 
    \hline 
        \textbf{ Bootstrapping } & A way to estimate a sampling distribution via resampling. We sample \textit{with replacement} from the original data. From this new distribution, we compute our statistic.\\ 
    \hline 
    \end{tabularx} 
\end{center}
